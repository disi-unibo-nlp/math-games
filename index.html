<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Phunny: Can Large Language Models Win the International Mathematical Games?">
  <meta name="keywords" content="MathVista, Math Vista">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Can Large Language Models Win the International Mathematical Games?</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <span class="mathvista" style="vertical-align: middle">MathGames</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Can Large Language Models Win the International Mathematical Games?
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://disi-unibo-nlp.github.io/people/">Alessio Cocchieri</a>,
            </span>
            <span class="author-block">
              <a href="https://disi-unibo-nlp.github.io/people/">Luca Ragazzi</a>,
            </span>
            <span class="author-block">
              <a href="https://disi-unibo-nlp.github.io/people/">Giuseppe Tagliavini</a>,
            </span>
            <span class="author-block">
              <a href="https://disi-unibo-nlp.github.io/people/">Lorenzo Tordi</a>,
            </span>
            <span class="author-block">
              <a href="https://disi-unibo-nlp.github.io/people/">Antonella Carbonaro</a>,
            </span>
            <span class="author-block">
              <a href="https://disi-unibo-nlp.github.io/people/">Gianluca Moro</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Bologna, Italy</span><br>
            <span class="paper-block"><b style="color:#f41c1c">EMNLP 2025 Main Track</b></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/disi-unibo-nlp/math-games"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/disi-unibo-nlp/MathGames"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ü§ó</p>
                      <!-- üîó -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="https://disi-unibo-nlp.github.io/math-games/#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://disi-unibo-nlp.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <!-- üíªüîó -->
                      <p style="font-size:18px">üåê</p>
                  </span>
                  <span>Research Team</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-top: -150px; margin-bottom: -100px;">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="images/radar.png" alt="overall" width="80%" />
              <p>
                <b>LLM accuracy across skill categories and age groups.</b> 
                Top: performance on text-only problems. 
                Bottom: performance on image-based problems (accuracy scale 0-70 for better visualization).
                Skills include Arithmetic (Ari), Logic (Log), Geometry (Geo), Combinatorics (Com), Algebra (Alg), and Pattern Recognition (Pat).
              </p>
            </div>
          </div>
          <!-- <div class="box m-5">
            <div class="content has-text-centered">
              <img src="images/abstract_figure.png" alt="overall2" width="35%"/>
              <p> <b>Human scores by age group in the 2024 Finals of the International Mathematical and Logical Games Championships (MathGames).</b> Markers indicate model performance for comparison.
              </p>
            </div>
          </div> -->
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in large language models (LLMs) have demonstrated strong mathematical reasoning abilities, even in visual contexts, with some models surpassing human performance on existing benchmarks. However, these benchmarks lack structured age categorization, clearly defined skill requirements, and‚Äîcrucially‚Äîwere not designed to assess human performance in international competitions.
          </p>
          <p> 
            To address these limitations, we introduce MathGames, a new benchmark of 2,183 high-quality mathematical problems (both text-only and multimodal) in an open-ended format, sourced from an international mathematical games championships. Spanning seven age groups and a skill-based taxonomy, MathGames enables a structured evaluation of LLMs' mathematical and logical reasoning abilities.
          </p>
          <p> 
            Our experiments reveal a substantial gap between state-of-the-art LLMs and human participants‚Äîeven 11-year-olds consistently outperform some of the strongest models‚Äîhighlighting the need for advancements. Further, our detailed error analysis offers valuable insights to guide future research.
          </p>
        </div>
      </div>
    </div>
</div>
</section>


<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mathvista">
    <span class="mathvista" style="vertical-align: middle">MathGames Dataset</span>
  </h1>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
        <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            <span class="mathvista">MathGames</span> is a carefully designed benchmark for evaluating the mathematical and logical reasoning abilities of foundation models across 2,183 high-quality, playful-style problems (1,389 textual problems and 794 multimodal problems) across different age categories in an open-ended format (i.e., without multiple-choice answers).
          </p>
          <p>
            You can download the dataset on <a href="https://huggingface.co/datasets/disi-unibo-nlp/MathGames" target="_blank">Hugging Face Dataset</a>.
          </p>

        </div>
      </div>
    </div>
    <div class="column is-full has-text-centered content">
    <!-- <p>One example for each reasoning skill required in <span class="mathvista">MathVista</span></p> -->
    <div id="results-carousel" class="carousel results-carousel">
        <div class="box m-5">
        <div class="content has-text-centered">
            <img src="images/stats.png" alt="contexts" width="40%"/>
            <p><b>Statistics of MathGames, including problem count and word lengths.</b> The overall count is not the sum of category-specific counts due to overlapping problems.</p>
        </div>
        </div>
    </div>
</div>
  </div>
</section>


<!-- LEADERBOARD SECTION -->
<section class="hero is-light is-small" id="leaderboard">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mathvista">
    <span class="mathvista" style="vertical-align: middle">Leaderboard on MathGames</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

        <h2 class="title is-3">Textual Problems</h2>
<div class="content">
  <b>CE, C1, C2, L1, L2, GP, HC:</b> Accuracy across age groups.  
  <br>
  <b>Avg:</b> Overall average.  
  <br>
  
  <table class="js-sort-table" id="results">
    <tr>
      <td><strong>Model</strong></td>
      <td><strong>CE</strong></td>
      <td><strong>C1</strong></td>
      <td><strong>C2</strong></td>
      <td><strong>L1</strong></td>
      <td><strong>L2</strong></td>
      <td><strong>GP</strong></td>
      <td><strong>HC</strong></td>
      <td><strong>Avg</strong></td>
    </tr>

    <tr><td colspan="9"><strong>Closed-Source</strong></td></tr>

    <tr><td>o3-mini-high üß†</td><td>83.8</td><td>82.0</td><td>81.7</td><td>80.6</td><td>79.2</td><td>77.1</td><td>73.3</td><td>79.7</td></tr>
    <tr><td>Gemini-2.0-Flash-T üß†</td><td>81.3</td><td>71.4</td><td>71.0</td><td>69.5</td><td>66.4</td><td>61.9</td><td>59.2</td><td>68.7</td></tr>
    <tr><td>Gemini-2.0-Flash</td><td>58.9</td><td>56.8</td><td>55.4</td><td>54.0</td><td>51.3</td><td>43.7</td><td>41.2</td><td>51.6</td></tr>
    <tr><td>Gemini-1.5-Pro</td><td>59.8</td><td>54.3</td><td>53.2</td><td>52.4</td><td>50.2</td><td>43.9</td><td>41.2</td><td>50.7</td></tr>
    <tr><td>Gemini-1.5-Flash</td><td>60.7</td><td>49.7</td><td>47.4</td><td>45.5</td><td>42.9</td><td>36.9</td><td>36.0</td><td>45.6</td></tr>
    <tr><td>GPT-4o</td><td>61.7</td><td>50.1</td><td>46.2</td><td>43.8</td><td>42.3</td><td>35.0</td><td>33.0</td><td>44.6</td></tr>
    <tr><td>GPT-4o-mini</td><td>49.5</td><td>42.2</td><td>42.8</td><td>41.5</td><td>39.8</td><td>31.4</td><td>30.0</td><td>40.4</td></tr>
    <tr><td>Gemini-1.5-Flash-8B</td><td>40.2</td><td>35.1</td><td>33.9</td><td>31.2</td><td>29.3</td><td>21.8</td><td>20.6</td><td>31.6</td></tr>

    <tr><td colspan="9"><strong>Open-Source &gt; 8B</strong></td></tr>

    <tr><td>DeepSeek-R1 üß†</td><td>85.0</td><td>77.3</td><td>75.9</td><td>74.7</td><td>72.7</td><td>69.7</td><td>69.0</td><td>74.9</td></tr>
    <tr><td>DeepSeek-V3</td><td>66.4</td><td>54.3</td><td>52.1</td><td>50.7</td><td>48.3</td><td>40.8</td><td>36.5</td><td>49.9</td></tr>
    <tr><td>Phi-4-14B *</td><td>66.4</td><td>51.9</td><td>48.1</td><td>46.0</td><td>43.7</td><td>37.0</td><td>32.2</td><td>46.5</td></tr>
    <tr><td>Phi-4-14B</td><td>59.8</td><td>50.4</td><td>45.9</td><td>43.6</td><td>41.1</td><td>33.6</td><td>30.0</td><td>43.5</td></tr>
    <tr><td>Qwen2.5-72B</td><td>53.3</td><td>48.4</td><td>45.2</td><td>43.3</td><td>41.4</td><td>34.4</td><td>29.6</td><td>42.2</td></tr>
    <tr><td>QwQ-32B üß†</td><td>56.1</td><td>43.5</td><td>40.0</td><td>37.3</td><td>34.4</td><td>25.4</td><td>23.2</td><td>37.1</td></tr>
    <tr><td>LLaMA-3.3-70B</td><td>44.9</td><td>41.5</td><td>39.7</td><td>37.3</td><td>35.7</td><td>26.3</td><td>26.2</td><td>35.9</td></tr>
    <tr><td>DeepSeek-R1-Qwen üß†</td><td>44.2</td><td>38.7</td><td>38.0</td><td>36.3</td><td>33.4</td><td>25.8</td><td>19.8</td><td>33.7</td></tr>

    <tr><td colspan="9"><strong>Open-Source ‚â§ 8B (Math-Specialized)</strong></td></tr>

    <tr><td>Qwen2.5-Math-7B * üîß</td><td>53.3</td><td>47.9</td><td>48.3</td><td>47.3</td><td>46.9</td><td>39.8</td><td>34.1</td><td>45.4</td></tr>
    <tr><td>Qwen2.5-Math-7B üîß</td><td>43.9</td><td>45.4</td><td>44.1</td><td>42.2</td><td>41.2</td><td>33.6</td><td>31.3</td><td>40.2</td></tr>
    <tr><td>NuminaMath-7B * üîß</td><td>43.0</td><td>38.8</td><td>38.0</td><td>36.7</td><td>35.3</td><td>26.7</td><td>24.5</td><td>34.7</td></tr>
    <tr><td>Qwen2.5-Math-7B *</td><td>40.7</td><td>37.0</td><td>38.3</td><td>36.7</td><td>35.6</td><td>27.5</td><td>26.1</td><td>34.6</td></tr>
    <tr><td>Qwen2.5-Math-7B</td><td>40.2</td><td>36.5</td><td>37.8</td><td>36.2</td><td>35.1</td><td>26.9</td><td>24.9</td><td>33.9</td></tr>
    <tr><td>NuminaMath-7B üîß</td><td>39.2</td><td>27.6</td><td>31.1</td><td>29.4</td><td>28.3</td><td>19.8</td><td>18.0</td><td>27.7</td></tr>
    <tr><td>NuminaMath-7B</td><td>28.8</td><td>25.6</td><td>24.9</td><td>24.1</td><td>23.1</td><td>25.4</td><td>22.4</td><td>24.9</td></tr>
    <tr><td>Mathstral-7B *</td><td>35.5</td><td>27.2</td><td>26.1</td><td>23.6</td><td>21.8</td><td>16.7</td><td>12.4</td><td>23.3</td></tr>
    <tr><td>NuminaMath-7B *</td><td>31.8</td><td>25.2</td><td>25.4</td><td>24.2</td><td>22.7</td><td>13.1</td><td>9.0</td><td>21.6</td></tr>
    <tr><td>DeepSeek-Math-7B * üîß</td><td>23.4</td><td>24.4</td><td>23.7</td><td>22.9</td><td>21.3</td><td>15.1</td><td>14.2</td><td>20.7</td></tr>
    <tr><td>Mathstral-7B</td><td>27.1</td><td>22.0</td><td>23.4</td><td>21.3</td><td>20.1</td><td>12.2</td><td>11.2</td><td>19.6</td></tr>
    <tr><td>DeepSeek-Math-7B *</td><td>21.3</td><td>21.6</td><td>21.9</td><td>20.7</td><td>19.6</td><td>13.2</td><td>10.2</td><td>18.4</td></tr>
    <tr><td>DeepSeek-Math-7B üîß</td><td>21.1</td><td>21.4</td><td>21.7</td><td>20.5</td><td>19.3</td><td>12.8</td><td>9.8</td><td>18.1</td></tr>
    <tr><td>DeepSeek-Math-7B</td><td>20.6</td><td>21.0</td><td>21.4</td><td>20.1</td><td>18.9</td><td>12.5</td><td>9.4</td><td>17.7</td></tr>
    <tr><td>ToRA-7B * üîß</td><td>12.2</td><td>11.6</td><td>12.1</td><td>11.5</td><td>11.1</td><td>7.6</td><td>6.4</td><td>10.4</td></tr>
    <tr><td>ToRA-7B üîß</td><td>6.5</td><td>11.1</td><td>12.4</td><td>11.8</td><td>11.3</td><td>9.3</td><td>7.7</td><td>10.0</td></tr>
  </table>

  <p style="font-size: 14px;">
    <strong>Note:</strong> üß† Reasoning-focused; * maj@8 instead of pass@1; üîß TIR mode.
  </p>
</div>

      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

        <h2 class="title is-3">Multimodal Problems</h2>
<div class="content">
  <b>CE, C1, C2, L1, L2, GP, HC:</b> Accuracy across age groups.  
  <br>
  <b>Avg:</b> Overall average.  
  <br>
  
  <table class="js-sort-table" id="results">
    <tr>
      <td><strong>Model</strong></td>
      <td><strong>CE</strong></td>
      <td><strong>C1</strong></td>
      <td><strong>C2</strong></td>
      <td><strong>L1</strong></td>
      <td><strong>L2</strong></td>
      <td><strong>GP</strong></td>
      <td><strong>HC</strong></td>
      <td><strong>Avg</strong></td>
    </tr>

    <tr><td colspan="9"><strong>Closed-Source</strong></td></tr>

    <tr>
      <td>Gemini-2.0-Flash-T üß†</td>
      <td>38.3</td><td>29.3</td><td>32.2</td><td>31.5</td><td>31.3</td><td>25.4</td><td>25.1</td><td>30.4</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Pro</td>
      <td>30.4</td><td>25.5</td><td>24.2</td><td>21.3</td><td>20.4</td><td>18.4</td><td>15.3</td><td>22.2</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Flash</td>
      <td>27.0</td><td>19.4</td><td>16.1</td><td>15.0</td><td>15.6</td><td>12.7</td><td>14.2</td><td>17.1</td>
    </tr>
    <tr>
      <td>GPT-4o</td>
      <td>25.2</td><td>20.4</td><td>17.8</td><td>14.8</td><td>12.9</td><td>10.2</td><td>10.9</td><td>16.0</td>
    </tr>
    <tr>
      <td>GPT-4o-mini</td>
      <td>23.5</td><td>18.5</td><td>16.1</td><td>13.4</td><td>12.1</td><td>10.2</td><td>11.5</td><td>15.0</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Flash-8B</td>
      <td>18.3</td><td>14.3</td><td>12.3</td><td>11.3</td><td>11.3</td><td>9.2</td><td>10.9</td><td>12.5</td>
    </tr>

    <tr><td colspan="9"><strong>Open-Source &gt; 8B</strong></td></tr>

    <tr>
      <td>InternVL-2.5-38B-MPO</td>
      <td>19.1</td><td>21.0</td><td>19.7</td><td>17.1</td><td>16.4</td><td>12.7</td><td>12.0</td><td>16.9</td>
    </tr>
    <tr>
      <td>InternVL-2.5-38B</td>
      <td>14.8</td><td>14.7</td><td>13.6</td><td>11.5</td><td>9.9</td><td>7.4</td><td>6.6</td><td>11.2</td>
    </tr>
    <tr>
      <td>QVQ-72B üß†</td>
      <td>20.0</td><td>11.8</td><td>8.9</td><td>7.5</td><td>7.1</td><td>6.7</td><td>6.6</td><td>9.8</td>
    </tr>
    <tr>
      <td>Qwen2-VL-72B</td>
      <td>14.8</td><td>12.5</td><td>11.2</td><td>8.8</td><td>7.5</td><td>6.0</td><td>3.8</td><td>9.2</td>
    </tr>
    <tr>
      <td>Pixtral-12B *</td>
      <td>12.2</td><td>6.4</td><td>5.9</td><td>5.2</td><td>4.8</td><td>5.3</td><td>4.4</td><td>6.3</td>
    </tr>
    <tr>
      <td>Pixtral-12B</td>
      <td>11.3</td><td>8.9</td><td>6.1</td><td>4.0</td><td>2.6</td><td>4.2</td><td>3.3</td><td>5.8</td>
    </tr>

    <tr><td colspan="9"><strong>Open-Source ‚â§ 8B</strong></td></tr>

    <tr>
      <td>Phi-3.5-4.2B *</td>
      <td>24.4</td><td>11.2</td><td>11.4</td><td>11.1</td><td>10.3</td><td>7.4</td><td>7.1</td><td>11.5</td>
    </tr>
    <tr>
      <td>Qwen2-VL-7B *</td>
      <td>13.0</td><td>11.5</td><td>10.8</td><td>10.2</td><td>9.3</td><td>9.2</td><td>7.7</td><td>10.2</td>
    </tr>
    <tr>
      <td>Qwen2-VL-7B</td>
      <td>13.9</td><td>9.2</td><td>10.0</td><td>8.8</td><td>7.9</td><td>4.6</td><td>4.9</td><td>8.5</td>
    </tr>
    <tr>
      <td>InternVL-2.5-8B *</td>
      <td>14.8</td><td>9.6</td><td>5.7</td><td>4.8</td><td>6.3</td><td>5.7</td><td>8.2</td><td>7.9</td>
    </tr>
    <tr>
      <td>InternVL-2.5-8B *</td>
      <td>11.3</td><td>9.6</td><td>7.8</td><td>6.3</td><td>5.9</td><td>3.5</td><td>3.3</td><td>6.8</td>
    </tr>
    <tr>
      <td>Phi-3.5-4.2B</td>
      <td>5.2</td><td>7.0</td><td>6.8</td><td>6.5</td><td>6.5</td><td>7.4</td><td>4.9</td><td>6.3</td>
    </tr>
  </table>

  <p style="font-size: 14px;">
    <strong>Note:</strong> üß† Reasoning-focused; * maj@8 instead of pass@1.
  </p>
</div>
    
  </div>
  </div>
  </div>
</section>



<!-- ERROR SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mathvista">
    <span class="mathvista" style="vertical-align: middle">Error Analysis</span>
  </h1>
  </div>
</section>



<section class="section">
  <div class="container">
    <div class="column is-full has-text-centered content">
    <div id="results-carousel" class="carousel results-carousel">
        <div class="box m-5">
        <div class="content has-text-centered">
            <img src="images/error_gemini_text.png" alt="contexts" width="80%"/>
            <p>Examples of errors made by Gemini models in text-only problems within MathGames.</p>
        </div>
        </div>
        <div class="box m-5">
        <div class="content has-text-centered">
            <img src="images/error_openai_multimodal.png" alt="contexts" width="80%"/>
            <p>Examples of errors made by OpenAI models in multimodal problems within MathGames.</p>
        </div>
        </div>
    </div>
</div>
  </div>
</section>


<!--bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@inproceedings{cocchieri-etal-2025-mathgames,
    title = "Can Large Language Models Win the International Mathematical Games?",
    author = "Cocchieri, Alessio  and
      Ragazzi, Luca  and
      Tagliavini, Giuseppe  and
      Tordi, Lorenzo  and
      Carbonaro, Antonella  and
      Moro, Gianluca",
    booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    abstract = "Recent advances in large language models (LLMs) have demonstrated strong mathematical reasoning abilities, even in visual contexts, with some models surpassing human performance on existing benchmarks. However, these benchmarks lack structured age categorization, clearly defined skill requirements, and‚Äîcrucially‚Äîwere not designed to assess human performance in international competitions. To address these limitations, we introduce MathGames, a new benchmark of 2,183 high-quality mathematical problems (both text-only and multimodal) in an open-ended format, sourced from an international mathematical games championships. Spanning seven age groups and a skill-based taxonomy, MathGames enables a structured evaluation of LLMs' mathematical and logical reasoning abilities. Our experiments reveal a substantial gap between state-of-the-art LLMs and human participants‚Äîeven 11-year-olds consistently outperform some of the strongest models‚Äîhighlighting the need for advancements. Further, our detailed error analysis offers valuable insights to guide future research. The data is publicly available at https://disi-unibo-nlp.github.io/math-games/."
  }</code></pre>
  </div>
</section>

<section>
  <div class="section" id="org-banners" style="display:flex">
    <a href="https://disi.unibo.it/en" target="_blank" rel="external">
        <img class="center-block org-banner" src="images/unibo-logo-big.png">
    </a>
  </div>
</section>

<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->
</footer>

</body>
</html>


<script>
document.addEventListener('DOMContentLoaded', () => {
  bulmaCarousel.attach('.carousel', {
    slidesToScroll: 1,
    slidesToShow: 1,
    autoplay: false,
    loop: false
  });
});
</script>